# Week 00

## progress

### day - 1

- implemented micrograd [grad.py]
- refreshed calc knowledge: derivatives, chain rule (it's everywhere) 
- operator overloading 
- traced graphs / used topo-sort (thought i was smart by implementing dfs first haha)  

### day - 2

- implemented MLP from scratch [mlp.py]
- applied gradient descent to minimize quadratic loss

### day - 3

- mastered micrograd & MLP (implement without looking at any references)
- added trigonometric functions to the engine
- completed 1st part of micrograd google colab challenge by karpathy [micrograd_exercises.ipynb]

### day - 4

- fully analyzed the whole micrograd repo
- completed google colab exercises for micrograd
- learned softmax, NLL loss, ReLU, Hinge loss, L2 penalty

### day - 5

vibe-coded an interactive 3d visualizer on top of micrograd using threejs. descent is not perfect yet. try it here: https://vivid-descent.vercel.app

### day - 6

< started makemore series, implemented bigram using manual nromalization
< trained a resnet-18 model based on PlantVillage dataset to detect diseases for hackathon https://tryapollo.vercel.app

### day - 7

day 7:
< built bigram using neural nets, implemented nll loss & softmax
< practiced more pytorch

## projects
    - https://tryapollo.vercel.app - plant disease detection model [pytorch]
    - https://vivid-descent.vercel.app - neural nets visualizer [threejs]
    - https://github.com/bilalsea2/cv-gallery - computer vision powered image gallery [mediapipe, nextjs]
